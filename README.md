# LangTrain

The goal of this repo is to have reproducible examples of how to fine tune a language model, and why you would do so.

Fine Tune LLM
1. kick tires on base LLM, prompt, response 
2. Collect dataset to fix
3. Eval more robustly
4. Fine tune on dataset
5. Kick tires again
6. Eval more robustly